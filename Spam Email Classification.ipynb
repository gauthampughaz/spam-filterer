{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Email Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have created a simple Feed-forward Neural Network model using Keras to classify spam emails based on this [dataset](https://spamassassin.apache.org/old/publiccorpus/). I have used NLP techniques inspired from this [notebook](https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb) and tweaked it to process and transform the data. Furthermore, I used Scikit-learn pipelines to perform data cleaning, data transformation, and modelling seamlessly on the training and testing datasets.\n",
    "\n",
    "Cross-validation score on training data: **98.35%**\n",
    "\n",
    "Final accuracy score on unseen test data: **99.20%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "import email.policy\n",
    "import re\n",
    "import urlextract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from os import path, listdir\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from text files of specific format and categorizing them into spam and ham emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./dataset\"\n",
    "\n",
    "def categorize_files(root_path):\n",
    "    \"\"\"\n",
    "    Categorizes files in the directories into spam and ham files\n",
    "    \"\"\"\n",
    "    \n",
    "    dirs = [dir_ for dir_ in listdir(PATH)]\n",
    "    \n",
    "    spam_files, ham_files = [], []\n",
    "    for dir_ in dirs:\n",
    "        if 'spam' in dir_:\n",
    "            for file in listdir(path.join(PATH, dir_)):\n",
    "                spam_files.append(path.join(PATH, dir_, file))\n",
    "        else:\n",
    "            for file in listdir(path.join(PATH, dir_)):\n",
    "                ham_files.append(path.join(PATH, dir_, file))\n",
    "                \n",
    "    return spam_files, ham_files\n",
    "\n",
    "spam_files, ham_files = categorize_files(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(file):\n",
    "    \"\"\"\n",
    "    Converts the email text into objects using Python's email module\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file, 'rb') as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    \n",
    "spam_emails = list(map(lambda x: parse_email(x), spam_files))\n",
    "ham_emails = list(map(lambda x: parse_email(x), ham_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Peeking the extracted data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUTURE TECH INTERNATIONAL\n",
      "\n",
      "SPECIAL OFFER that \"BLOWS AWAY TRADITIONAL MARKETING\" - Advertising Age.\n",
      "\n",
      "The most powerful fully exportable CD Fax Database on the market\n",
      "1,500,000 Business Fax Numbers\n",
      "\n",
      "OVER 1.5 MILLION FAX NUMBERS FULLY EXPORTABLE!\n",
      "Usually Sells for $295. For a limited time only we are offering them for:\n",
      "\n",
      "ONLY $49.95 USD\n",
      "(Never before have this many fax numbers been sold for so cheap)\n",
      "\n",
      "TARGETED EMAIL LIST\n",
      "100 MILLION EMAIL ADDRESSES\n",
      "Usually sells for $195.00. For a limited time only we are offering them for:\n",
      "\n",
      "ONLY $79.95 USD\n",
      "\n",
      "SPECIAL PACKAGE DEAL FOR BOTH DIRECTORIES:\n",
      "\n",
      "ONLY $99.95 USD\n",
      "\n",
      "MORE THAN 34 CATEGORIES SUCH AS:\n",
      "-Multi level marketers\n",
      "-Opportunity Seekers\n",
      "-Telephone Area Code\n",
      "-Country, City, State, etc...\n",
      "-Travel & Vacations\n",
      "-Opt-in\n",
      "-People intersted in investments\n",
      "-People or businesses who spent more than $1000 on the web in the last 2 months\n",
      "-AND MANY MORE\n",
      "\n",
      "*Everything o n this disk is in TEXT file format and fully Exportable.\n",
      "*The CD is as easy to use as browsing your C drive in Explorer.\n",
      "\n",
      "TO ORDER YOURS CALL 416-467-6585\n",
      "\n",
      "OR FAX THE FORM BELOW TO 416-467-8986\n",
      "\n",
      "ORDER FORM (Please PRINT clearly)\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Name:\n",
      "\n",
      "Company Name:\n",
      "\n",
      "Email Address:\n",
      "\n",
      "Tel#:\n",
      "\n",
      "Shipping Address:\n",
      "\n",
      "City:                                   Zip/Postal Code:\n",
      "\n",
      "Country:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "PRODUCT:\n",
      "\n",
      "[] Email Address CDROM (100 Million Addresses) $79.95\n",
      "[] Fax Directory (1.5 Million Business Fax Numbers) $49.95\n",
      "[] SPECIAL PACKAGE DEAL (Both Fax & Email Directories) $99.95\n",
      "\n",
      "SHIPPING OPTIONS:\n",
      "\n",
      "[] Regular Mail (1 - 2 weeks delivery) $5.95\n",
      "[] Priority Mail (2 - 5 business days) $12.95\n",
      "[] Fedex Overnite $25.95\n",
      "\n",
      "TOTAL AMOUNT TO BE BILLED TO CREDIT CARD: $\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "CREDIT CARD INFO:\n",
      "\n",
      "[] VISA  [] MASTERCARD  [] AMERICAN EXPRESS\n",
      "\n",
      "Card #:\n",
      "\n",
      "Expiry Date:\n",
      "\n",
      "Name on Card:\n",
      "\n",
      "Billing Address:\n",
      "\n",
      "Authorized Signature:\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "PLEASE FAX THIS FORM BACK TO 416-467-8986\n",
      "\n",
      "TO ORDER BY MAIL:\n",
      "\n",
      "PLEASE send the ORDER FORM BACK and PRODUCT FORM withy a money order payable to FUTURE TECH INTERNATIONAL for the balance to:\n",
      "\n",
      "FUTURE TECH INTERNATIONAL\n",
      "IMPORT EXPORT COMPANY\n",
      "85 THORNCLIFFE PARK DRIVE SUITE 3602\n",
      "TORONTO, ONTARIO\n",
      "CANADA (POSTAL) M4H 1L6\n",
      "\n",
      "FOR ANY QUESTIONS PLEASE FEEL FREE TO CALL US AT 1-416-467-6585\n",
      "\n",
      "*PROVIDE YOUR EMAIL ADDRESS SO THAT WE CAN SEND YOU A RECEIPT FOR YOUR TRANSACTION\n",
      "For email removals sjshdhd-39e2@yahoo.com\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[1000].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiya, I always seem to get errors when I do an \"apt update\", is this a \n",
      "problem on the repository itself, or on my end, or possibly a timeout in \n",
      "the connection due to my connection being a crappy modem?\n",
      "\n",
      "[root@spawn root]# apt-get update\n",
      "Hit http://apt.nixia.no redhat/7.2/i386/base/pkglist.gnomehide\n",
      "Hit http://apt.freshrpms.net redhat/7.2/i386/base/pkglist.os\n",
      "Ign http://apt.freshrpms.net redhat/7.2/i386 release.os\n",
      "Err http://apt.freshrpms.net redhat/7.2/i386/base/pkglist.updates\n",
      "  Bad header line\n",
      "Hit http://apt.freshrpms.net redhat/7.2/i386 release.updates\n",
      "Err http://apt.freshrpms.net redhat/7.2/i386/base/pkglist.freshrpms\n",
      "  400 Bad Request\n",
      "Err http://apt.freshrpms.net redhat/7.2/i386 release.freshrpms\n",
      "  Bad header line\n",
      "Hit http://apt.freshrpms.net redhat/7.2/i386/base/srclist.freshrpms\n",
      "Ign http://apt.nixia.no redhat/7.2/i386 release.gnomehide\n",
      "Ign http://apt.nixia.no redhat/7.2/i386/base/mirrors\n",
      "Hit http://apt.freshrpms.net redhat/7.2/i386 release.freshrpms\n",
      "Ign http://apt.freshrpms.net redhat/7.2/i386/base/mirrors\n",
      "Ign http://apt.freshrpms.net redhat/7.2/i386/base/mirrors\n",
      "Ign http://apt.freshrpms.net redhat/7.2/i386/base/mirrors\n",
      "Ign http://apt.freshrpms.net redhat/7.2/i386/base/mirrors\n",
      "Failed to fetch \n",
      "http://apt.freshrpms.net/redhat/7.2/i386/base/pkglist.updates\n",
      "  Bad header line\n",
      "Failed to fetch \n",
      "http://apt.freshrpms.net/redhat/7.2/i386/base/pkglist.freshrpms\n",
      "  400 Bad Request\n",
      "Failed to fetch \n",
      "http://apt.freshrpms.net/redhat/7.2/i386/base/release.freshrpms\n",
      "  Bad header line\n",
      "\n",
      "                                    -- \\m/ --\n",
      "  \"...if I seem super human I have been misunderstood.\" (c) Dream Theater\n",
      "         mark@talios.com - ICQ: 1934853 JID: talios@myjabber.net\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "RPM-List mailing list <RPM-List@freshrpms.net>\n",
      "http://lists.freshrpms.net/mailman/listinfo/rpm-list\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the distribution of spam and ham emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Spam emails: 1898\n",
      "Number of Ham emails: 2501\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Spam emails: {len(spam_emails)}\")\n",
    "print(f\"Number of Ham emails: {len(ham_emails)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the different types of email structures in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(email, list):\n",
    "        return f\"\"\"multipart({', '.join(get_email_structure(sub_email) \n",
    "                                        for sub_email in payload)})\"\"\"\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "    \n",
    "def structure_counter(emails):\n",
    "    counter = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        counter[structure] += 1\n",
    "        \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('text/plain', 817), ('text/html', 772), ('multipart/alternative', 169), ('multipart/mixed', 99), ('multipart/related', 40), ('text/plain charset=us-ascii', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(structure_counter(spam_emails).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('text/plain', 2409), ('multipart/signed', 68), ('multipart/mixed', 10), ('multipart/alternative', 9), ('multipart/related', 3), ('multipart/report', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(structure_counter(ham_emails).most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the diiferent headers present in an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path: <rpm-zzzlist-admin@freshrpms.net>\n",
      "\n",
      "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
      "\n",
      "Received: from localhost (jalapeno [127.0.0.1])\tby jmason.org (Postfix) with ESMTP id 9D98A16EFC\tfor <jm@localhost>; Mon,  9 Sep 2002 18:00:20 +0100 (IST)\n",
      "\n",
      "Received: from jalapeno [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor jm@localhost (single-drop); Mon, 09 Sep 2002 18:00:20 +0100 (IST)\n",
      "\n",
      "Received: from auth02.nl.egwn.net (auth02.nl.egwn.net [193.172.5.4]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g11MGS812405 for    <jm-rpm@jmason.org>; Fri, 1 Feb 2002 22:16:28 GMT\n",
      "\n",
      "Received: from auth02.nl.egwn.net (localhost [127.0.0.1]) by    auth02.nl.egwn.net (8.11.6/8.11.6/EGWN) with ESMTP id g11MF0308879;    Fri, 1 Feb 2002 23:15:00 +0100\n",
      "\n",
      "Received: from drone4.qsi.net.nz (drone4-svc-skyt.qsi.net.nz    [202.89.128.4]) by auth02.nl.egwn.net (8.11.6/8.11.6/EGWN) with SMTP id    g11MEh308869 for <rpm-list@freshrpms.net>; Fri, 1 Feb 2002 23:14:43 +0100\n",
      "\n",
      "Received: (qmail 95088 invoked by uid 0); 1 Feb 2002 22:15:02 -0000\n",
      "\n",
      "Received: from unknown (HELO se7en.org) ([202.89.145.8]) (envelope-sender    <mark@talios.com>) by 0 (qmail-ldap-1.03) with SMTP for    <rpm-list@freshrpms.net>; 1 Feb 2002 22:15:02 -0000\n",
      "\n",
      "Received: from spawn.se7en.org ([10.0.0.3]) by se7en.org with esmtp (Exim    3.12 #1 (Debian)) id 16WnZF-00036C-00 for <rpm-list@freshrpms.net>;    Sat, 02 Feb 2002 12:58:05 +1300\n",
      "\n",
      "From: Mark Derricutt <mark@talios.com>\n",
      "\n",
      "To: rpm-zzzlist@freshrpms.net\n",
      "\n",
      "Subject: problems with apt update\n",
      "\n",
      "Message-Id: <14220000.1012602017@spawn.se7en.org>\n",
      "\n",
      "X-Mailer: Mulberry/2.1.2 (Linux/x86)\n",
      "\n",
      "MIME-Version: 1.0\n",
      "\n",
      "Content-Type: text/plain; charset=\"us-ascii\"; format=\"flowed\"\n",
      "\n",
      "Content-Transfer-Encoding: 7bit\n",
      "\n",
      "Content-Disposition: inline\n",
      "\n",
      "Sender: rpm-zzzlist-admin@freshrpms.net\n",
      "\n",
      "Errors-To: rpm-zzzlist-admin@freshrpms.net\n",
      "\n",
      "X-Beenthere: rpm-zzzlist@freshrpms.net\n",
      "\n",
      "X-Mailman-Version: 2.0.1\n",
      "\n",
      "Precedence: bulk\n",
      "\n",
      "Reply-To: rpm-zzzlist@freshrpms.net\n",
      "\n",
      "List-Help: <mailto:rpm-zzzlist-request@freshrpms.net?subject=help>\n",
      "\n",
      "List-Post: <mailto:rpm-zzzlist@freshrpms.net>\n",
      "\n",
      "List-Subscribe: <http://lists.freshrpms.net/mailman/listinfo/rpm-zzzlist>,    <mailto:rpm-list-request@freshrpms.net?subject=subscribe>\n",
      "\n",
      "List-Id: Freshrpms RPM discussion list <rpm-zzzlist.freshrpms.net>\n",
      "\n",
      "List-Unsubscribe: <http://lists.freshrpms.net/mailman/listinfo/rpm-zzzlist>,    <mailto:rpm-list-request@freshrpms.net?subject=unsubscribe>\n",
      "\n",
      "List-Archive: <http://lists.freshrpms.net/pipermail/rpm-zzzlist/>\n",
      "\n",
      "X-Original-Date: Sat, 02 Feb 2002 11:20:17 +1300\n",
      "\n",
      "Date: Sat, 02 Feb 2002 11:20:17 +1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for header, value in ham_emails[1].items():\n",
    "    print(f\"{header}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the different types of headers present in both spam and non-spam emails as a set for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = set()\n",
    "\n",
    "for spam_email in spam_emails:\n",
    "    for header in spam_email.keys():\n",
    "        HEADERS.add(header)\n",
    "        \n",
    "for ham_email in ham_emails:\n",
    "    for header in ham_email.keys():\n",
    "        HEADERS.add(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test set using **StratifiedShuffleSplit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3519,)\n",
      "X_test shape: (880,)\n",
      "y_train shape: (3519,)\n",
      "y_test shape: (880,)\n"
     ]
    }
   ],
   "source": [
    "X = np.r_[spam_emails, ham_emails]\n",
    "y = np.r_[np.ones(len(spam_emails)), np.zeros(len(ham_emails))]\n",
    "\n",
    "stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in stratified_splitter.split(X, y):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the HTML tags from the emails and converting them to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_plain_text(email):\n",
    "    \n",
    "    text = re.sub('<head.*?>.*?</head>', '', email, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    \n",
    "    return unescape(text)\n",
    "\n",
    "def email_to_text(email):\n",
    "    for part in email.walk(): # to walk through the parts of an email\n",
    "        c_type = part.get_content_type()\n",
    "        \n",
    "        if not c_type in ['text/plain', 'text/html']: # skip if email content is not text\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content() # get the content of the email\n",
    "        except:\n",
    "            content = str(part.get_payload()) # in case of encoding issues\n",
    "        if c_type == 'text/plain':\n",
    "            return content # return the content in case of plain text\n",
    "        else:\n",
    "            return html_to_plain_text(content) # other return after removing HTML tags\n",
    "    \n",
    "    return \"no content\" # if the email doesn't contain any text content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex patterns and other constants to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS_PATTERN = re.compile(f\"({'|'.join(HEADERS)})\" + r\"\\s*:\\s*.*\")\n",
    "PUNCTUATIONS_PATTERN = re.compile(r\"[^a-zA-Z0-9\\s]\")\n",
    "NUMBERS_PATTERN = re.compile(r\"\\d+(?:\\.\\d+)?(?:[eE]-?\\d+)?\")\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "URL_PATTERN = re.compile((r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}\"\n",
    "                          r\"|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}\"\n",
    "                          r\"|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}\"\n",
    "                          r\"|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}\"\n",
    "                          r\"|[a-zA-Z0-9]+\\.[a-zA-Z]{2,})\"))\n",
    "UNWANTED_WORDS = re.compile(r\"(html|doctype|head|xxx|mime|transitionalen|http)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom data transformer to clean and process the contents of the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailContentTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, to_lower=True, remove_punctuation=True,\n",
    "                 replace_URLs=True, replace_num=True, stem_words=True,\n",
    "                 remove_stopwords=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.to_lower = to_lower\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_URLs = replace_URLs\n",
    "        self.replace_num = replace_num\n",
    "        self.stem_words = stem_words\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        if self.stem_words:\n",
    "            self.stemmer = PorterStemmer()\n",
    "    \n",
    "    def get_stemmed_words(self, email_content):\n",
    "        \"\"\"\n",
    "        Returns the content with words stemmed\n",
    "        \"\"\"\n",
    "        stemmed_words = \"\"\n",
    "        for word in email_content.split():\n",
    "            if len(word) <= 20:\n",
    "                if self.remove_stopwords:\n",
    "                    if word not in STOPWORDS:\n",
    "                        stemmed_words += f\"{self.stemmer.stem(word)} \"\n",
    "                else:\n",
    "                    stemmed_words += f\"{self.stemmer.stem(word)} \"\n",
    "        \n",
    "        return stemmed_words\n",
    "    \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Returns an array of strings with transformed emails\n",
    "        \"\"\"\n",
    "        X_transformed = []\n",
    "        for index, email in enumerate(X): # loops through every email in the dataset\n",
    "            email_content = email_to_text(email) # convert the email object to plain text\n",
    "            \n",
    "            if self.replace_URLs: # replaces the URLs with word URL\n",
    "                email_content = URL_PATTERN.sub(\" URL \", email_content)\n",
    "            if self.strip_headers: # removes the headers from the text\n",
    "                email_content = HEADERS_PATTERN.sub(\"\", email_content)\n",
    "            if self.to_lower: # converts the content to lower case\n",
    "                email_content = email_content.lower()\n",
    "            if self.remove_punctuation: # removes the punctuations\n",
    "                email_content = PUNCTUATIONS_PATTERN.sub(\"\", email_content)\n",
    "            if self.replace_num: # replaces the numbers with word NUMBER\n",
    "                email_content = NUMBERS_PATTERN.sub(\" NUMBER \", email_content)\n",
    "            email_content = UNWANTED_WORDS.sub(\" \", email_content) # removes the unwanted words\n",
    "            if self.stem_words: # stems the words in the email content\n",
    "                email_content = self.get_stemmed_words(email_content)\n",
    "                \n",
    "            X_transformed.append(email_content)\n",
    "            \n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom pipeline for data preparation and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipeline = Pipeline([\n",
    "    ('email_content_transformer', EmailContentTransformer()), # cleans the data\n",
    "    ('tfidf_transformer', TfidfVectorizer()) # transforms the cleaned content into tf-idf vectors\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build the feed-forward neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    Builds and returns the model\n",
    "    \"\"\"\n",
    "    input_shape = len(data_prep_pipeline['tfidf_transformer']\n",
    "                      .get_feature_names()) # to dynamically get the shape of input data as it varies \n",
    "                                            # during cross validation and final model training\n",
    "    model = Sequential()\n",
    "    # Adding layers to the model\n",
    "    model.add(Dense(units=30, activation='relu',\n",
    "                    input_shape=(input_shape,)))\n",
    "    model.add(Dense(units=20, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Specifying the loss function and optimizer\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validating the model with 5 folds to know how the model performs on the unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "\n",
      "Epoch 1/3\n",
      "2815/2815 [==============================] - 2s 885us/step - loss: 0.3556 - accuracy: 0.8817\n",
      "Epoch 2/3\n",
      "2815/2815 [==============================] - 2s 833us/step - loss: 0.0412 - accuracy: 0.9915\n",
      "Epoch 3/3\n",
      "2815/2815 [==============================] - 2s 828us/step - loss: 0.0150 - accuracy: 0.9968\n",
      "\n",
      "Score for Fold 1: 0.9872\n",
      "\n",
      "Fold 2\n",
      "\n",
      "Epoch 1/3\n",
      "2815/2815 [==============================] - 2s 873us/step - loss: 0.3742 - accuracy: 0.8810\n",
      "Epoch 2/3\n",
      "2815/2815 [==============================] - 2s 823us/step - loss: 0.0387 - accuracy: 0.9922\n",
      "Epoch 3/3\n",
      "2815/2815 [==============================] - 2s 827us/step - loss: 0.0128 - accuracy: 0.9975\n",
      "\n",
      "Score for Fold 2: 0.9844\n",
      "\n",
      "Fold 3\n",
      "\n",
      "Epoch 1/3\n",
      "2815/2815 [==============================] - 2s 834us/step - loss: 0.3195 - accuracy: 0.9190\n",
      "Epoch 2/3\n",
      "2815/2815 [==============================] - 2s 802us/step - loss: 0.0356 - accuracy: 0.9915\n",
      "Epoch 3/3\n",
      "2815/2815 [==============================] - 2s 644us/step - loss: 0.0141 - accuracy: 0.9968\n",
      "\n",
      "Score for Fold 3: 0.9886\n",
      "\n",
      "Fold 4\n",
      "\n",
      "Epoch 1/3\n",
      "2815/2815 [==============================] - 2s 881us/step - loss: 0.3715 - accuracy: 0.9552\n",
      "Epoch 2/3\n",
      "2815/2815 [==============================] - 2s 845us/step - loss: 0.0418 - accuracy: 0.9922\n",
      "Epoch 3/3\n",
      "2815/2815 [==============================] - 2s 848us/step - loss: 0.0149 - accuracy: 0.9968\n",
      "\n",
      "Score for Fold 4: 0.9872\n",
      "\n",
      "Fold 5\n",
      "\n",
      "Epoch 1/3\n",
      "2816/2816 [==============================] - 2s 637us/step - loss: 0.3598 - accuracy: 0.9332\n",
      "Epoch 2/3\n",
      "2816/2816 [==============================] - 2s 605us/step - loss: 0.0369 - accuracy: 0.9940\n",
      "Epoch 3/3\n",
      "2816/2816 [==============================] - 2s 604us/step - loss: 0.0112 - accuracy: 0.9979\n",
      "\n",
      "Score for Fold 5: 0.9701\n",
      "\n",
      "CV score: 0.9835\n"
     ]
    }
   ],
   "source": [
    "# Using StratifiedKFold to ensure that folds contain samples from both classes\n",
    "stratified_folds = StratifiedKFold(n_splits=5, shuffle=True,\n",
    "                                   random_state=42)\n",
    "scores = []\n",
    "for fold, indices in enumerate(stratified_folds.split(X_train, y_train)):\n",
    "    X_train_, y_train_ = X_train[indices[0]], y_train[indices[0]]\n",
    "    X_test_, y_test_ = X_train[indices[1]], y_train[indices[1]]\n",
    "    \n",
    "    # Creating a model pipeline to train and predict data along with data preparation\n",
    "    model_pipeline = Pipeline([\n",
    "        ('data_prep_pipeline', data_prep_pipeline),\n",
    "        ('model', KerasClassifier(build_model, epochs=3, batch_size=16))\n",
    "    ])\n",
    "    print(f\"Fold {fold + 1}\", end=\"\\n\\n\")\n",
    "    model_pipeline.fit(X_train_, y_train_)\n",
    "    predictions = model_pipeline.predict(X_test_)\n",
    "    score = accuracy_score(y_test_, predictions)\n",
    "    scores.append(score)\n",
    "    print(f\"\\nScore for Fold {fold + 1}: {score:.4f}\",\n",
    "          end=\"\\n\\n\")\n",
    "\n",
    "print(f\"CV score: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a new model to the entire training data and estimating the model's score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3519/3519 [==============================] - 3s 959us/step - loss: 0.3025 - accuracy: 0.9542\n",
      "Epoch 2/5\n",
      "3519/3519 [==============================] - 3s 935us/step - loss: 0.0268 - accuracy: 0.9943\n",
      "Epoch 3/5\n",
      "3519/3519 [==============================] - 3s 935us/step - loss: 0.0108 - accuracy: 0.9972\n",
      "Epoch 4/5\n",
      "3519/3519 [==============================] - 3s 933us/step - loss: 0.0076 - accuracy: 0.9972\n",
      "Epoch 5/5\n",
      "3519/3519 [==============================] - 3s 918us/step - loss: 0.0062 - accuracy: 0.9986\n",
      "\n",
      "Accuracy score on test data:0.9920\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('data_prep_pipeline', data_prep_pipeline),\n",
    "    ('model', KerasClassifier(build_model, epochs=5, batch_size=16))\n",
    "])\n",
    "\n",
    "# Fitting a model to the data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "# Making predictions with the trained model\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "\n",
    "print((f\"\\nAccuracy score on test data:\"\n",
    "       f\"{accuracy_score(y_test, predictions):.4f}\"))                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
